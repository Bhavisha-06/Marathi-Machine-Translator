{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80226d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"engtomar.csv\")\n",
    "english_sentences = data[\"English\"].tolist()\n",
    "marathi_sentences = data[\"Marathi\"].tolist()\n",
    "marathi_sentences = [str(sentence) for sentence in marathi_sentences]\n",
    "english_sentences = [str(sentence) for sentence in english_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e091a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_eng = Tokenizer()\n",
    "tokenizer_eng.fit_on_texts(english_sentences)\n",
    "eng_seq = tokenizer_eng.texts_to_sequences(english_sentences)\n",
    "\n",
    "tokenizer_ma = Tokenizer()\n",
    "tokenizer_ma.fit_on_texts(marathi_sentences)\n",
    "ma_seq = tokenizer_ma.texts_to_sequences(marathi_sentences)\n",
    "\n",
    "vocab_size_eng = len(tokenizer_eng.word_index) + 1\n",
    "vocab_size_ma = len(tokenizer_ma.word_index) + 1\n",
    "\n",
    "# Padding\n",
    "max_length = max(len(seq) for seq in eng_seq + ma_seq)\n",
    "eng_seq_padded = pad_sequences(eng_seq, maxlen=max_length, padding='post')\n",
    "ma_seq_padded = pad_sequences(ma_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36708969",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 512\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_length,))\n",
    "enc_emb = Embedding(input_dim=vocab_size_eng, output_dim=embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_length,))\n",
    "dec_emb_layer = Embedding(input_dim=vocab_size_ma, output_dim=embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size_ma, activation='softmax')\n",
    "output = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74867869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - 12s 196ms/step - loss: 1.6277 - accuracy: 0.8820 - val_loss: 0.9445 - val_accuracy: 0.8969\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 10s 191ms/step - loss: 0.8451 - accuracy: 0.8979 - val_loss: 0.8728 - val_accuracy: 0.8975\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 10s 190ms/step - loss: 0.7733 - accuracy: 0.8987 - val_loss: 0.9029 - val_accuracy: 0.8954\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 11s 195ms/step - loss: 0.7578 - accuracy: 0.8983 - val_loss: 0.8689 - val_accuracy: 0.8984\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 10s 194ms/step - loss: 0.7171 - accuracy: 0.9008 - val_loss: 0.8801 - val_accuracy: 0.8989\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 11s 197ms/step - loss: 0.7008 - accuracy: 0.9011 - val_loss: 0.8807 - val_accuracy: 0.8991\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 10s 194ms/step - loss: 0.6842 - accuracy: 0.9015 - val_loss: 0.8867 - val_accuracy: 0.8992\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 11s 200ms/step - loss: 0.6696 - accuracy: 0.9018 - val_loss: 0.8964 - val_accuracy: 0.8991\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 11s 199ms/step - loss: 0.6539 - accuracy: 0.9029 - val_loss: 0.9028 - val_accuracy: 0.8998\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 11s 196ms/step - loss: 0.6385 - accuracy: 0.9038 - val_loss: 0.9226 - val_accuracy: 0.8997\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 11s 207ms/step - loss: 0.6237 - accuracy: 0.9042 - val_loss: 0.9229 - val_accuracy: 0.8997\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 12s 219ms/step - loss: 0.6101 - accuracy: 0.9054 - val_loss: 0.9349 - val_accuracy: 0.8982\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 13s 241ms/step - loss: 0.5955 - accuracy: 0.9057 - val_loss: 0.9529 - val_accuracy: 0.8995\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 16s 292ms/step - loss: 0.5780 - accuracy: 0.9066 - val_loss: 0.9644 - val_accuracy: 0.9003\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 21s 383ms/step - loss: 0.5620 - accuracy: 0.9074 - val_loss: 0.9750 - val_accuracy: 0.8997\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 23s 433ms/step - loss: 0.5472 - accuracy: 0.9078 - val_loss: 0.9871 - val_accuracy: 0.9004\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 22s 408ms/step - loss: 0.5309 - accuracy: 0.9093 - val_loss: 0.9964 - val_accuracy: 0.9007\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 20s 374ms/step - loss: 0.5146 - accuracy: 0.9100 - val_loss: 1.0010 - val_accuracy: 0.8997\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 18s 334ms/step - loss: 0.4990 - accuracy: 0.9111 - val_loss: 1.0158 - val_accuracy: 0.9009\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 18s 325ms/step - loss: 0.4841 - accuracy: 0.9122 - val_loss: 1.0228 - val_accuracy: 0.9015\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 17s 320ms/step - loss: 0.4680 - accuracy: 0.9137 - val_loss: 1.0269 - val_accuracy: 0.9015\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 17s 312ms/step - loss: 0.4525 - accuracy: 0.9150 - val_loss: 1.0459 - val_accuracy: 0.9012\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 17s 316ms/step - loss: 0.4369 - accuracy: 0.9169 - val_loss: 1.0571 - val_accuracy: 0.9005\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 19s 359ms/step - loss: 0.4206 - accuracy: 0.9194 - val_loss: 1.0619 - val_accuracy: 0.9011\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 19s 357ms/step - loss: 0.4043 - accuracy: 0.9210 - val_loss: 1.0724 - val_accuracy: 0.9008\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 19s 345ms/step - loss: 0.3882 - accuracy: 0.9242 - val_loss: 1.0783 - val_accuracy: 0.9017\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 18s 340ms/step - loss: 0.3732 - accuracy: 0.9265 - val_loss: 1.0961 - val_accuracy: 0.9011\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 18s 330ms/step - loss: 0.3592 - accuracy: 0.9294 - val_loss: 1.0954 - val_accuracy: 0.9016\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 17s 319ms/step - loss: 0.3422 - accuracy: 0.9330 - val_loss: 1.1093 - val_accuracy: 0.9013\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 17s 314ms/step - loss: 0.3266 - accuracy: 0.9364 - val_loss: 1.1108 - val_accuracy: 0.9012\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 17s 307ms/step - loss: 0.3099 - accuracy: 0.9410 - val_loss: 1.1225 - val_accuracy: 0.9020\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 17s 308ms/step - loss: 0.2952 - accuracy: 0.9444 - val_loss: 1.1296 - val_accuracy: 0.9020\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 17s 307ms/step - loss: 0.2790 - accuracy: 0.9479 - val_loss: 1.1402 - val_accuracy: 0.9026\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 17s 311ms/step - loss: 0.2636 - accuracy: 0.9517 - val_loss: 1.1508 - val_accuracy: 0.9026\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 17s 309ms/step - loss: 0.2488 - accuracy: 0.9560 - val_loss: 1.1535 - val_accuracy: 0.9033\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 17s 312ms/step - loss: 0.2348 - accuracy: 0.9590 - val_loss: 1.1598 - val_accuracy: 0.9030\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 17s 310ms/step - loss: 0.2199 - accuracy: 0.9630 - val_loss: 1.1674 - val_accuracy: 0.9028\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 17s 314ms/step - loss: 0.2066 - accuracy: 0.9660 - val_loss: 1.1758 - val_accuracy: 0.9032\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 17s 316ms/step - loss: 0.1935 - accuracy: 0.9688 - val_loss: 1.1801 - val_accuracy: 0.9035\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 17s 318ms/step - loss: 0.1811 - accuracy: 0.9706 - val_loss: 1.1899 - val_accuracy: 0.9050\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 19s 350ms/step - loss: 0.1677 - accuracy: 0.9733 - val_loss: 1.1965 - val_accuracy: 0.9042\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 18s 333ms/step - loss: 0.1563 - accuracy: 0.9749 - val_loss: 1.1996 - val_accuracy: 0.9037\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 18s 329ms/step - loss: 0.1465 - accuracy: 0.9766 - val_loss: 1.2061 - val_accuracy: 0.9032\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 18s 337ms/step - loss: 0.1452 - accuracy: 0.9745 - val_loss: 1.2084 - val_accuracy: 0.9039\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 18s 342ms/step - loss: 0.1306 - accuracy: 0.9774 - val_loss: 1.2150 - val_accuracy: 0.9041\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 18s 341ms/step - loss: 0.1186 - accuracy: 0.9793 - val_loss: 1.2170 - val_accuracy: 0.9039\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 18s 333ms/step - loss: 0.1098 - accuracy: 0.9800 - val_loss: 1.2257 - val_accuracy: 0.9044\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 18s 333ms/step - loss: 0.1015 - accuracy: 0.9813 - val_loss: 1.2335 - val_accuracy: 0.9044\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 18s 328ms/step - loss: 0.0951 - accuracy: 0.9813 - val_loss: 1.2404 - val_accuracy: 0.9041\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 18s 330ms/step - loss: 0.0892 - accuracy: 0.9823 - val_loss: 1.2388 - val_accuracy: 0.9045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x295912550>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(eng_seq_padded, ma_seq_padded, test_size=0.2)\n",
    "model.fit([X_train, X_train], y_train, validation_data=([X_val, X_val], y_val), epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68bf1622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavishachaudhari/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"translation_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a720bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Input: How are you\n",
      "Translated: तू कसा आहेस                              \n",
      "I have lot of work\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Input: I have lot of work\n",
      "Translated: मला आज काम आहे                            \n",
      "Let me go\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Input: Let me go\n",
      "Translated: मला जाऊ द्या                              \n"
     ]
    }
   ],
   "source": [
    "def translate_sentence(sentence):\n",
    "    seq = tokenizer_eng.texts_to_sequences([sentence])\n",
    "    padded = pad_sequences(seq, maxlen=max_length, padding='post')\n",
    "    translated = np.argmax(model.predict([padded, padded]), axis=-1)\n",
    "    \n",
    "    translated_sentence = []\n",
    "    for i in translated[0]:\n",
    "        if i in tokenizer_ma.index_word:\n",
    "            translated_sentence.append(tokenizer_ma.index_word[i])\n",
    "        else:\n",
    "            translated_sentence.append(' ') \n",
    "        \n",
    "    return ' '.join(translated_sentence)\n",
    "while True:\n",
    "    input_sentence = input()\n",
    "    translated_sentence = translate_sentence(input_sentence)\n",
    "    print(f\"Input: {input_sentence}\")\n",
    "    print(f\"Translated: {translated_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f8f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e80071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b6a73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb20bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede55b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63872a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d7a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197ce0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295bb05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9d91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
